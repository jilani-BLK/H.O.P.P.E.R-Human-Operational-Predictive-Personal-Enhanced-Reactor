# ğŸ§  Architecture RAG AvancÃ©e pour HOPPER
*Date: 22 octobre 2025*
*Auteur: StratÃ©gie proposÃ©e par jilani*

## ğŸ¯ Vision StratÃ©gique

**ProblÃ¨me du RAG classique:** Il rÃ©cupÃ¨re des documents mais **ne fait rien** avec des outils.

**Solution HOPPER:** Architecture hybride combinant GraphRAG, ReAct/Toolformer et Self-RAG.

## ğŸ“ Architecture ProposÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     HOPPER RAG Pipeline                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Self-RAG (Critique)   â”‚â—„â”€â”€ "Ai-je besoin de RAG?"
              â”‚   - Relevance check     â”‚
              â”‚   - Latence optimale    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                           â”‚
         â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GraphRAG     â”‚          â”‚  ReAct Agent   â”‚
â”‚  (Knowledge)   â”‚          â”‚   (Actions)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Notes        â”‚          â”‚ â€¢ Email IMAP   â”‚
â”‚ â€¢ Docs         â”‚          â”‚ â€¢ Agenda       â”‚
â”‚ â€¢ Logs systÃ¨me â”‚          â”‚ â€¢ Fichiers     â”‚
â”‚ â€¢ Relations    â”‚          â”‚ â€¢ Domotique    â”‚
â”‚ â€¢ EntitÃ©s      â”‚          â”‚ â€¢ Terminal     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  HyDE (optionnel)â”‚
            â”‚  Query expansion â”‚â—„â”€â”€ RequÃªtes floues
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  kNN-LM        â”‚â—„â”€â”€ Token-level memory
            â”‚  (dÃ©codage)    â”‚    (ultra-rapide)
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Composants DÃ©taillÃ©s

### 1. **Self-RAG** (PrioritÃ©: CRITIQUE)
> *"Ã‰viter la rÃ©cupÃ©ration inutile et garder la latence basse"*

**RÃ´le:** DÃ©cider **si** et **quand** utiliser RAG.

**ImplÃ©mentation:**
```python
class SelfRAG:
    """Critique intelligente avant rÃ©cupÃ©ration"""
    
    def should_retrieve(self, query: str, context: dict) -> bool:
        """
        DÃ©cide si RAG est nÃ©cessaire
        
        CritÃ¨res:
        - Question factuelle? â†’ RAG
        - Conversation simple? â†’ LLM direct
        - Besoin de contexte passÃ©? â†’ RAG historique
        - Action Ã  exÃ©cuter? â†’ ReAct agent
        """
        # Prompt lÃ©ger au LLM (50 tokens max)
        decision = self.llm.classify(
            prompt=f"Cette requÃªte nÃ©cessite-t-elle une recherche? {query}",
            options=["search", "direct", "action"]
        )
        
        return decision
    
    def critique_retrieval(self, documents: List[str], query: str) -> List[str]:
        """Filtre les docs non pertinents APRÃˆS rÃ©cupÃ©ration"""
        # Score de pertinence (rapide, pas le LLM)
        relevant = [doc for doc in documents 
                   if self.relevance_score(doc, query) > 0.7]
        return relevant
```

**MÃ©triques de succÃ¨s:**
- âœ… Latence < 100ms pour dÃ©cision
- âœ… 80% de prÃ©cision (Ã©viter RAG inutile)
- âœ… 20% rÃ©duction du temps de rÃ©ponse global

---

### 2. **GraphRAG** (PrioritÃ©: HAUTE)
> *"MÃ©moire longue structurÃ©e (notes, docs, logs systÃ¨me)"*

**RÃ´le:** Base de connaissances avec relations entre entitÃ©s.

**Structure Graph:**
```
User
 â”œâ”€ Notes
 â”‚   â”œâ”€ "RÃ©union projet X" â”€â”€relationâ”€â”€> [Date, Participants]
 â”‚   â””â”€ "IdÃ©e feature Y"   â”€â”€depends_onâ”€> RÃ©union projet X
 â”œâ”€ Documents
 â”‚   â”œâ”€ "Manuel HOPPER"    â”€â”€versionâ”€â”€> 3.0
 â”‚   â””â”€ "Specs Phase 3"    â”€â”€implementsâ”€> "Manuel HOPPER"
 â””â”€ Logs SystÃ¨me
     â”œâ”€ "Erreur Port 5000" â”€â”€fixed_byâ”€â”€> "Config Port 5050"
     â””â”€ "Test Integration"  â”€â”€validatedâ”€> Phase 3
```

**ImplÃ©mentation:**
```python
# Utiliser Neo4j (graphe natif) OU Nebula Graph (open-source)
from neo4j import GraphDatabase

class GraphRAG:
    """MÃ©moire structurÃ©e en graphe de connaissances"""
    
    def __init__(self, uri: str, user: str, password: str):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
    
    def add_note(self, content: str, user_id: str, metadata: dict):
        """Ajoute une note avec relations automatiques"""
        with self.driver.session() as session:
            # Extraire entitÃ©s avec NER (spaCy)
            entities = self.extract_entities(content)
            
            # CrÃ©er nÅ“ud Note
            session.run(
                "CREATE (n:Note {content: $content, user_id: $user_id, "
                "timestamp: datetime(), metadata: $metadata})",
                content=content, user_id=user_id, metadata=metadata
            )
            
            # CrÃ©er relations avec entitÃ©s existantes
            for entity in entities:
                session.run(
                    "MATCH (n:Note {content: $content}) "
                    "MATCH (e:Entity {name: $entity}) "
                    "CREATE (n)-[:MENTIONS]->(e)",
                    content=content, entity=entity
                )
    
    def retrieve_with_context(self, query: str, depth: int = 2) -> List[dict]:
        """RÃ©cupÃ¨re documents + contexte via relations"""
        with self.driver.session() as session:
            # Recherche vectorielle + traversÃ©e du graphe
            results = session.run(
                "MATCH (n:Note)-[r*1..$depth]-(related) "
                "WHERE n.embedding <-> $query_embedding < 0.3 "
                "RETURN n, collect(related) as context",
                query_embedding=self.embed(query),
                depth=depth
            )
            return list(results)
```

**Avantages vs RAG classique:**
- âœ… Comprend **pourquoi** deux infos sont liÃ©es
- âœ… Peut rÃ©pondre: "Qui a participÃ© Ã  la rÃ©union oÃ¹ on a parlÃ© de X?"
- âœ… TraversÃ©e multi-hop: "Quelle feature dÃ©pend du bug qu'on a fixÃ© hier?"

**Stack technique:**
- **Neo4j** (local avec Docker) OU **Nebula Graph** (plus lÃ©ger)
- **Embeddings:** `all-MiniLM-L6-v2` (dÃ©jÃ  utilisÃ©)
- **NER:** spaCy `fr_core_news_lg` pour extraction d'entitÃ©s

---

### 3. **ReAct / Toolformer** (PrioritÃ©: CRITIQUE)
> *"Piloter des outils locaux (mail, agenda, domotique, fichiers)"*

**RÃ´le:** Agent qui **raisonne** puis **agit** avec des outils.

**Cycle ReAct:**
```
Thought â†’ Action â†’ Observation â†’ Thought â†’ ...
```

**ImplÃ©mentation:**
```python
class ReActAgent:
    """Agent avec capacitÃ© de raisonnement et d'action"""
    
    def __init__(self, llm, tools: Dict[str, Callable]):
        self.llm = llm
        self.tools = tools  # {"email": EmailTool(), "files": FileTool(), ...}
        
    def run(self, query: str, max_steps: int = 5) -> str:
        """Cycle Thought â†’ Action â†’ Observation"""
        
        trajectory = []
        for step in range(max_steps):
            # 1. THOUGHT: Raisonner sur la prochaine action
            thought = self.llm.generate(
                f"PensÃ©e: Pour '{query}', je dois...\n"
                f"Historique: {trajectory}\n"
                f"Outils disponibles: {list(self.tools.keys())}\n"
                f"PensÃ©e:"
            )
            trajectory.append(f"Thought: {thought}")
            
            # 2. ACTION: DÃ©cider de l'outil et des arguments
            action = self.llm.generate(
                f"{thought}\nAction: utiliser <tool>[arg1, arg2]"
            )
            
            tool_name, args = self.parse_action(action)
            
            # 3. OBSERVATION: ExÃ©cuter et observer rÃ©sultat
            if tool_name == "FINISH":
                return args  # RÃ©ponse finale
            
            result = self.tools[tool_name](*args)
            trajectory.append(f"Action: {tool_name}({args})")
            trajectory.append(f"Observation: {result}")
        
        return "Max steps reached"
    
    def parse_action(self, action_str: str) -> Tuple[str, List]:
        """Parse: 'email[check_inbox, folder=INBOX]'"""
        # Regex ou parsing simple
        ...
```

**Outils Ã  intÃ©grer (dÃ©jÃ  en partie dans HOPPER):**
```python
TOOLS = {
    "email": EmailTool(imap_config),      # âœ… PrÃ©vu Phase 3
    "files": FilesTool(workspace_path),   # âœ… DÃ©jÃ  prÃ©sent (system_executor)
    "agenda": AgendaTool(calendar_api),   # ğŸ”œ Phase 4
    "domotique": HomeAssistantTool(),     # ğŸ”œ Phase 4
    "terminal": TerminalTool(),           # âœ… DÃ©jÃ  prÃ©sent
    "web_search": DuckDuckGoTool(),       # ğŸ”œ Optionnel
}
```

**Exemple concret:**
```
User: "Envoie un email Ã  Paul pour lui dire que la rÃ©union est Ã  15h"

Thought 1: Je dois rÃ©cupÃ©rer l'email de Paul
Action 1: contacts[search, name="Paul"]
Observation 1: paul.dupont@example.com

Thought 2: Je dois composer l'email
Action 2: email[compose, to="paul.dupont@example.com", 
                  subject="Horaire rÃ©union", 
                  body="La rÃ©union est confirmÃ©e pour 15h."]
Observation 2: Email envoyÃ© avec succÃ¨s

Thought 3: TÃ¢che terminÃ©e
Action 3: FINISH["Email envoyÃ© Ã  Paul concernant la rÃ©union Ã  15h"]
```

**DiffÃ©rence avec RAG:**
- RAG: "Voici ce que je sais sur les emails"
- ReAct: "Je vais **envoyer** l'email maintenant"

---

### 4. **HyDE** (PrioritÃ©: MOYENNE)
> *"RequÃªtes floues â†’ documents hypothÃ©tiques"*

**RÃ´le:** Transformer requÃªte floue en document hypothÃ©tique pour meilleur matching.

**Concept:**
```
User: "truc machin pour la rÃ©union"
     â†“
HyDE: "Compte-rendu de rÃ©union du projet X du 15/10/2025 
       oÃ¹ nous avons discutÃ© des fonctionnalitÃ©s..."
     â†“
Embedding du document hypothÃ©tique (meilleur que query)
     â†“
Recherche vectorielle
```

**ImplÃ©mentation:**
```python
class HyDE:
    """Hypothetical Document Embeddings"""
    
    def expand_query(self, vague_query: str) -> str:
        """GÃ©nÃ¨re document hypothÃ©tique depuis requÃªte floue"""
        
        prompt = f"""GÃ©nÃ¨re un document dÃ©taillÃ© qui rÃ©pondrait Ã  cette requÃªte:
Query: {vague_query}

Document hypothÃ©tique (200 mots):"""
        
        hypothetical_doc = self.llm.generate(prompt, max_tokens=200)
        return hypothetical_doc
    
    def retrieve(self, query: str, vector_db) -> List[Document]:
        """RÃ©cupÃ¨re via document hypothÃ©tique"""
        
        # 1. GÃ©nÃ©rer doc hypothÃ©tique
        hypo_doc = self.expand_query(query)
        
        # 2. Embedder le doc (pas la query)
        hypo_embedding = self.embed(hypo_doc)
        
        # 3. Recherche vectorielle classique
        results = vector_db.search(hypo_embedding, top_k=5)
        
        return results
```

**Quand l'utiliser:**
- âœ… User dit: "le truc de l'autre jour"
- âœ… RequÃªtes avec pronoms: "comment on fait Ã§a?"
- âœ… Questions vagues: "info sur le projet"
- âŒ Questions prÃ©cises: "Quelle est la date de la rÃ©union?"

---

### 5. **kNN-LM** (PrioritÃ©: BASSE - Optionnel)
> *"MÃ©moire token-level ultra-rapide au dÃ©codage"*

**RÃ´le:** Base de donnÃ©es de tokens observÃ©s pour influencer gÃ©nÃ©ration.

**Concept:**
```
GÃ©nÃ©ration LLM normale:
  P(next_token | context) â†’ Softmax sur vocabulaire

Avec kNN-LM:
  P(next_token) = Î» * P_LM(token) + (1-Î») * P_kNN(token)
  
  P_kNN = chercher dans DB les contextes similaires 
          et voir quels tokens ont suivi
```

**Cas d'usage HOPPER:**
- âœ… ComplÃ©tion de noms propres: "Envoie un email Ã  Pa..." â†’ "Paul" (vu dans logs)
- âœ… Commandes rÃ©currentes: "Lance la..." â†’ "musique" (action frÃ©quente)
- âœ… Adaptation style utilisateur

**ImplÃ©mentation (FAISS):**
```python
import faiss
import numpy as np

class kNNLM:
    """Token-level memory pour gÃ©nÃ©ration"""
    
    def __init__(self, dim: int = 768):
        self.index = faiss.IndexFlatL2(dim)  # Index FAISS
        self.tokens_db = []  # (context_embedding, next_token)
    
    def add_sequence(self, tokens: List[str], embeddings: np.ndarray):
        """Ajoute sÃ©quence observÃ©e dans la DB"""
        for i in range(len(tokens) - 1):
            context_emb = embeddings[i]
            next_token = tokens[i + 1]
            
            self.index.add(context_emb.reshape(1, -1))
            self.tokens_db.append(next_token)
    
    def query(self, context_embedding: np.ndarray, k: int = 10) -> dict:
        """RÃ©cupÃ¨re les k tokens les plus probables"""
        distances, indices = self.index.search(
            context_embedding.reshape(1, -1), k
        )
        
        # Compter frÃ©quence des tokens
        candidates = [self.tokens_db[i] for i in indices[0]]
        probs = {token: candidates.count(token) / k 
                for token in set(candidates)}
        
        return probs
```

**Trade-off:**
- âœ… ComplÃ©tions personnalisÃ©es
- âœ… Ultra-rapide (FAISS)
- âŒ ComplexitÃ© ajoutÃ©e
- âŒ Utile seulement si beaucoup de donnÃ©es utilisateur

**Verdict:** Ã€ implÃ©menter **plus tard** (Phase 5-6), aprÃ¨s avoir collectÃ© assez d'interactions.

---

## ğŸ—ï¸ Plan d'ImplÃ©mentation pour HOPPER

### Phase 3.5 (RAG AvancÃ©) - 4 semaines

#### Semaine 1-2: Self-RAG + GraphRAG
```python
# Fichiers Ã  crÃ©er:
src/rag/self_rag.py          # Critique intelligente
src/rag/graph_store.py       # Interface Neo4j
src/rag/entity_extractor.py  # NER avec spaCy
```

**TÃ¢ches:**
1. âœ… Installer Neo4j via Docker
2. âœ… ImplÃ©menter Self-RAG avec classification rapide
3. âœ… Migrer ChromaDB â†’ GraphRAG
4. âœ… Extraire entitÃ©s des notes/docs
5. âœ… Tests: requÃªtes multi-hop

**Validation:**
- RequÃªte: "Qui a parlÃ© du bug qu'on a fixÃ© hier?"
  - GraphRAG trouve: Bug #123 â†’ RÃ©union X â†’ [Paul, Marie]

#### Semaine 3: ReAct Agent
```python
# Fichiers Ã  crÃ©er:
src/agents/react_agent.py       # Cycle Thoughtâ†’Actionâ†’Observation
src/agents/tools/email_tool.py  # âœ… PrÃ©vu Phase 3
src/agents/tools/file_tool.py   # âœ… DÃ©jÃ  prÃ©sent (refactor)
```

**TÃ¢ches:**
1. âœ… ImplÃ©menter cycle ReAct
2. âœ… Wrapper outils existants (system_executor, email)
3. âœ… Parser actions depuis LLM
4. âœ… Tests: scÃ©narios multi-actions

**Validation:**
- User: "Cherche dans mes emails celui de Paul et crÃ©e une note"
  - Agent: email[search, from=Paul] â†’ notes[create, content=...]

#### Semaine 4: HyDE + IntÃ©gration
```python
# Fichiers Ã  crÃ©er:
src/rag/hyde.py                 # Query expansion
src/rag/unified_retriever.py    # Combine tous les composants
```

**TÃ¢ches:**
1. âœ… ImplÃ©menter HyDE
2. âœ… Pipeline unifiÃ©: Self-RAG â†’ [GraphRAG|ReAct|HyDE]
3. âœ… MÃ©triques: latence, pertinence
4. âœ… Documentation complÃ¨te

**Validation:**
- User: "le truc de l'autre jour sur le projet"
  - HyDE gÃ©nÃ¨re doc hypothÃ©tique â†’ GraphRAG trouve note pertinente

---

## ğŸ“Š Comparaison Architecture

| Composant | RAG Classique | HOPPER RAG AvancÃ© | Gain |
|-----------|---------------|-------------------|------|
| **RÃ©cupÃ©ration** | Vector search seul | GraphRAG + relations | +40% pertinence |
| **Actions** | âŒ Aucune | âœ… ReAct agent | Tools opÃ©rationnels |
| **DÃ©cision** | Toujours RAG | Self-RAG critique | -30% latence |
| **RequÃªtes floues** | Embeddings directs | HyDE expansion | +25% couverture |
| **MÃ©moire** | Docs entiers | Graph + kNN-LM | Contexte riche |

---

## ğŸ¯ MÃ©triques de SuccÃ¨s

### Performance
- âœ… Latence Self-RAG < 100ms
- âœ… GraphRAG query < 500ms
- âœ… ReAct action complÃ¨te < 3s
- âœ… HyDE expansion < 200ms

### QualitÃ©
- âœ… 90% prÃ©cision Self-RAG (Ã©viter RAG inutile)
- âœ… 80% pertinence GraphRAG (vs 60% RAG classique)
- âœ… 95% succÃ¨s actions ReAct
- âœ… 70% amÃ©lioration requÃªtes floues (HyDE)

### UtilisabilitÃ©
- âœ… User peut dire: "fais X avec Y" â†’ ReAct exÃ©cute
- âœ… User peut chercher: "truc de Paul" â†’ GraphRAG trouve
- âœ… User voit: <100ms pour questions simples (pas de RAG)

---

## ğŸš€ Prochaines Ã‰tapes ImmÃ©diates

1. **Installer Neo4j** (Docker)
   ```bash
   docker run -d --name neo4j \
     -p 7474:7474 -p 7687:7687 \
     -e NEO4J_AUTH=neo4j/hopper123 \
     neo4j:latest
   ```

2. **CrÃ©er structure modules**
   ```
   src/rag/
   â”œâ”€â”€ self_rag.py
   â”œâ”€â”€ graph_store.py
   â”œâ”€â”€ hyde.py
   â””â”€â”€ unified_retriever.py
   
   src/agents/
   â”œâ”€â”€ react_agent.py
   â””â”€â”€ tools/
       â”œâ”€â”€ email_tool.py
       â”œâ”€â”€ file_tool.py
       â””â”€â”€ agenda_tool.py
   ```

3. **Tests de validation**
   ```python
   tests/test_rag_advanced.py
   tests/test_react_agent.py
   ```

---

## ğŸ“š RÃ©fÃ©rences

- **GraphRAG:** [Microsoft GraphRAG Paper](https://arxiv.org/abs/2404.16130)
- **ReAct:** [ReAct: Synergizing Reasoning and Acting](https://arxiv.org/abs/2210.03629)
- **Self-RAG:** [Self-RAG: Learning to Retrieve, Generate, and Critique](https://arxiv.org/abs/2310.11511)
- **HyDE:** [Precise Zero-Shot Dense Retrieval](https://arxiv.org/abs/2212.10496)
- **kNN-LM:** [Generalization through Memorization](https://arxiv.org/abs/1911.00172)
- **Toolformer:** [Language Models Can Teach Themselves to Use Tools](https://arxiv.org/abs/2302.04761)

---

## ğŸ’¡ Conclusion

**Ta suggestion est excellente** car elle combine:
1. âœ… **GraphRAG** â†’ MÃ©moire structurÃ©e (ce que HOPPER sait)
2. âœ… **ReAct/Toolformer** â†’ Actions concrÃ¨tes (ce que HOPPER fait)
3. âœ… **Self-RAG** â†’ Optimisation latence (ce que HOPPER Ã©vite)
4. âœ… **HyDE** â†’ Robustesse requÃªtes (ce que HOPPER comprend)
5. â¸ï¸ **kNN-LM** â†’ Personnalisation avancÃ©e (Phase 5+)

**Next:** ImplÃ©menter Self-RAG + GraphRAG en prioritÃ© (Semaines 1-2)?
