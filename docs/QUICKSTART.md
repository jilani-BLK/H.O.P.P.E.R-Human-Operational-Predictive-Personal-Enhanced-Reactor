# Guide de D√©marrage Rapide - HOPPER

Ce guide vous permettra de lancer HOPPER en 15 minutes.

## ‚ö° Installation Express

### 1. Pr√©requis

```bash
# V√©rifier Docker
docker --version  # >= 20.10
docker-compose --version  # >= 1.29

# V√©rifier Python
python3 --version  # >= 3.10
```

### 2. Cloner et Configurer

```bash
# Cloner le projet
git clone https://github.com/jilani-BLK/H.O.P.P.E.R-Human-Operational-Predictive-Personal-Enhanced-Reactor.git
cd HOPPER

# Copier la configuration
cp .env.example .env

# Cr√©er les dossiers de donn√©es
mkdir -p data/models data/logs data/vector_store
```

### 3. Mode D√©marrage Rapide (Sans Mod√®le LLM)

Pour tester imm√©diatement l'architecture:

```bash
# Lancer les services en mode simulation
docker-compose up -d

# Attendre le d√©marrage complet (~30 secondes)
sleep 30

# V√©rifier l'√©tat
curl http://localhost:5000/health
```

**R√©sultat attendu**:
```json
{
  "status": "healthy",
  "services": {
    "llm": false,       # Mode simulation
    "system_executor": true,
    "stt": true,
    "tts": true,
    "auth": true,
    "connectors": true
  }
}
```

### 4. Premier Test

```bash
# Installer le CLI
chmod +x hopper-cli.py
python3 hopper-cli.py --health

# Commande de test
python3 hopper-cli.py "Bonjour HOPPER"

# Mode interactif
python3 hopper-cli.py -i
```

## üéØ Installation Compl√®te (Avec LLM)

### Option A: T√©l√©charger un Mod√®le Pr√©-entra√Æn√©

```bash
# Installer huggingface-cli
pip install huggingface-hub

# T√©l√©charger LLaMA 2 7B (GGUF quantifi√©)
huggingface-cli download TheBloke/Llama-2-7B-Chat-GGUF \
  llama-2-7b-chat.Q4_K_M.gguf \
  --local-dir data/models

# Ou Mistral 7B (plus performant pour la taille)
huggingface-cli download TheBloke/Mistral-7B-Instruct-v0.2-GGUF \
  mistral-7b-instruct-v0.2.Q4_K_M.gguf \
  --local-dir data/models
```

### Option B: T√©l√©chargement Manuel

1. Aller sur [HuggingFace](https://huggingface.co/models)
2. Chercher "GGUF Chat" ou "Instruct"
3. T√©l√©charger un fichier `.gguf` quantifi√© (Q4_K_M ou Q5_K_M)
4. Placer dans `data/models/`

### Configurer le Mod√®le

```bash
# √âditer .env
nano .env

# Modifier cette ligne:
LLM_MODEL_PATH=/data/models/votre-modele.gguf

# Red√©marrer le service LLM
docker-compose restart llm
```

## üß™ Tests Fonctionnels

### Test 1: Module Syst√®me

```bash
python3 hopper-cli.py "Cr√©e un fichier de test"

# V√©rifier
ls /tmp/hopper_test.txt
```

### Test 2: LLM (si mod√®le charg√©)

```bash
python3 hopper-cli.py "Quelle est la capitale de la France?"

# R√©ponse attendue:
# HOPPER: La capitale de la France est Paris...
```

### Test 3: API REST

```bash
# Tester directement l'API
curl -X POST http://localhost:5000/command \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Bonjour, qui es-tu?",
    "user_id": "test_user"
  }'
```

### Test 4: Tous les Services

```bash
# V√©rifier chaque service
for port in 5000 5001 5002 5003 5004 5005 5006; do
  echo "Service sur port $port:"
  curl -s http://localhost:$port/health | jq
done
```

## üêõ R√©solution de Probl√®mes

### Probl√®me: Service ne d√©marre pas

```bash
# Voir les logs
docker-compose logs service_name

# Exemple pour l'orchestrateur
docker-compose logs orchestrator

# Logs en temps r√©el
docker-compose logs -f
```

### Probl√®me: Erreur "Cannot connect"

```bash
# V√©rifier que Docker tourne
docker ps

# V√©rifier les ports
netstat -an | grep LISTEN | grep "500[0-6]"

# Red√©marrer tous les services
docker-compose restart
```

### Probl√®me: "Out of Memory" (LLM)

```bash
# Utiliser un mod√®le plus petit (7B au lieu de 13B)
# Ou augmenter Docker RAM allocation

# Sur macOS:
# Docker Desktop ‚Üí Settings ‚Üí Resources ‚Üí Memory: 8GB+
```

### Probl√®me: Mod√®le LLM lent

```bash
# V√©rifier que le GPU est utilis√©
docker-compose logs llm | grep "GPU"

# Augmenter GPU layers dans .env
LLM_GPU_LAYERS=35  # Au lieu de 30
```

## üé® Personnalisation Rapide

### Changer la Voix TTS (macOS)

```bash
# Lister les voix disponibles
say -v "?"

# Modifier le service TTS
# Dans docker/tts.Dockerfile ou en appelant l'API avec un param√®tre
```

### Ajouter un Utilisateur

```bash
# Via le CLI (futur)
python3 hopper-cli.py --enroll "VotreNom"

# Ou API
curl -X POST http://localhost:5005/enroll \
  -F "user_id=VotreNom" \
  -F "audio=@sample.wav"
```

## üìä Monitoring en Direct

```bash
# Dashboard simple
watch -n 2 'curl -s http://localhost:5000/health | jq'

# Utilisation ressources
docker stats

# Logs combin√©s
docker-compose logs -f --tail=50
```

## üöÄ Commandes Utiles

```bash
# Arr√™ter tous les services
docker-compose down

# Arr√™ter et nettoyer
docker-compose down -v

# Rebuild complet
docker-compose up --build -d

# Red√©marrer un service sp√©cifique
docker-compose restart orchestrator

# Acc√©der √† un conteneur
docker-compose exec orchestrator /bin/bash

# Voir la consommation
docker-compose top
```

## üéØ Prochaines √âtapes

1. **Tester diff√©rentes commandes** via le CLI interactif
2. **Ajouter votre propre mod√®le LLM** optimis√©
3. **Configurer les connecteurs** (email, calendrier)
4. **Impl√©menter l'authentification vocale**
5. **D√©velopper des plugins personnalis√©s**

## üìö Ressources

- [Documentation Compl√®te](README.md)
- [Architecture D√©taill√©e](ARCHITECTURE.md)
- [API Reference](API.md)
- [Guide du D√©veloppeur](DEVELOPMENT.md)

## ‚úÖ Checklist de D√©marrage

- [ ] Docker install√© et fonctionnel
- [ ] Projet clon√© et configur√©
- [ ] Services d√©marr√©s (docker-compose up)
- [ ] Health check pass√©
- [ ] CLI test√© en mode interactif
- [ ] Premi√®re commande syst√®me r√©ussie
- [ ] (Optionnel) Mod√®le LLM t√©l√©charg√© et configur√©
- [ ] (Optionnel) Tests API pass√©s

---

**F√©licitations!** üéâ HOPPER est op√©rationnel sur votre machine.

Pour toute question: [Issues GitHub](https://github.com/jilani-BLK/H.O.P.P.E.R-Human-Operational-Predictive-Personal-Enhanced-Reactor/issues)
