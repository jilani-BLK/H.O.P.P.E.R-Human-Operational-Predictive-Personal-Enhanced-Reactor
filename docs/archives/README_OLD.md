# HOPPER - Human Operational Predictive Personal Enhanced Reactor

![Version](https://img.shields.io/badge/version-0.1.0--alpha-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Platform](https://img.shields.io/badge/platform-macOS%20|%20Linux-lightgrey)

Assistant personnel intelligent autonome fonctionnant entiÃ¨rement en local, conÃ§u pour apprendre de lui-mÃªme et traiter des tÃ¢ches en temps rÃ©el.

## ğŸ¯ Objectifs

HOPPER est envisagÃ© comme un assistant personnel intelligent qui:

- **Apprend de lui-mÃªme** via apprentissage par renforcement et fine-tuning local
- **Fonctionne 100% en local** sur votre machine (aucune dÃ©pendance cloud)
- **Prend des dÃ©cisions autonomes** et propose des suggestions proactives
- **S'intÃ¨gre avec de multiples systÃ¨mes** (OS, web, IoT, autres machines)
- **Optimise les performances** avec C/C++ pour le calcul et Python pour l'IA
- **Garantit la sÃ©curitÃ©** avec authentification vocale/faciale

## ğŸ—ï¸ Architecture

### Architecture Microservices

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   UTILISATEUR                            â”‚
â”‚              (CLI / Voix / Interface)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ORCHESTRATEUR CENTRAL (Python)              â”‚
â”‚  â€¢ Analyse d'intention                                   â”‚
â”‚  â€¢ Gestion du contexte conversationnel                   â”‚
â”‚  â€¢ Routage des commandes                                 â”‚
â”‚  â€¢ RÃ¨gles heuristiques et dÃ©cisions                      â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚    â”‚    â”‚    â”‚    â”‚    â”‚
      â–¼    â–¼    â–¼    â–¼    â–¼    â–¼
   â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â”€â”
   â”‚LLMâ”‚â”‚SYSâ”‚â”‚STTâ”‚â”‚TTSâ”‚â”‚AUTâ”‚â”‚CONNâ”‚
   â”‚   â”‚â”‚EXEâ”‚â”‚   â”‚â”‚   â”‚â”‚H  â”‚â”‚    â”‚
   â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜
   C++   C   Py   Py   Py   Py
```

### Modules Principaux

1. **Orchestrateur Central** (Python)
   - Cerveau de HOPPER qui coordonne tous les services
   - Analyse d'intention et routage des commandes
   - Gestion du contexte conversationnel
   - Logique de dÃ©cision et rÃ¨gles heuristiques

2. **Moteur LLM** (C++ avec llama.cpp)
   - ModÃ¨le de langage local (LLaMA 2 / Mistral)
   - InfÃ©rence optimisÃ©e sur GPU Apple Silicon
   - Contexte Ã©tendu via Retrieval Augmented Generation
   - Fine-tuning local continu

3. **Module d'ExÃ©cution SystÃ¨me** (C)
   - Actions systÃ¨me directes (fichiers, processus)
   - Performances optimales en C pur
   - Serveur HTTP lÃ©ger avec libmicrohttpd

4. **Module STT** (Python + Whisper)
   - Reconnaissance vocale locale
   - Support multilingue (franÃ§ais prioritaire)
   - BasÃ© sur OpenAI Whisper

5. **Module TTS** (Python)
   - SynthÃ¨se vocale naturelle
   - Voix franÃ§aise de qualitÃ©
   - Latence minimale

6. **Module d'Authentification** (Python)
   - Reconnaissance vocale du locuteur
   - Reconnaissance faciale (optionnel)
   - Gestion multi-utilisateurs

7. **Connecteurs** (Python)
   - Email (IMAP/SMTP)
   - Calendrier (Google Calendar, iCloud)
   - IoT (MQTT, Zigbee)
   - Services web et API externes

## ğŸš€ Installation

### PrÃ©requis

- **SystÃ¨me d'exploitation**: macOS (M1/M2/M3), Linux
- **RAM**: Minimum 16 Go, recommandÃ© 32 Go+
- **Espace disque**: 50 Go (pour les modÃ¨les)
- **Docker**: Version 20.10+
- **Python**: 3.10 ou supÃ©rieur

### Installation Rapide

```bash
# 1. Cloner le repository
git clone https://github.com/jilani-BLK/H.O.P.P.E.R-Human-Operational-Predictive-Personal-Enhanced-Reactor.git
cd HOPPER

# 2. Copier le fichier de configuration
cp .env.example .env

# 3. TÃ©lÃ©charger un modÃ¨le LLM (exemple avec LLaMA 2 7B)
mkdir -p data/models
# TÃ©lÃ©charger depuis HuggingFace ou utiliser un modÃ¨le existant
# Exemple: https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF

# 4. Lancer les services
docker-compose up -d

# 5. VÃ©rifier l'Ã©tat
docker-compose ps
```

### VÃ©rification de l'Installation

```bash
# VÃ©rifier la santÃ© des services
curl http://localhost:5000/health

# Ou utiliser le CLI
python hopper-cli.py --health
```

## ğŸ’» Utilisation

### Mode CLI (Ligne de Commande)

```bash
# Mode interactif
python hopper-cli.py -i

# Commande directe
python hopper-cli.py "Quelle heure est-il?"

# CrÃ©er un alias pour faciliter l'utilisation
alias hopper="python /chemin/vers/hopper-cli.py"
hopper "Ouvre l'application Notes"
```

### Exemples de Commandes

```bash
# SystÃ¨me
hopper "CrÃ©e un fichier test.txt"
hopper "Liste les fichiers du rÃ©pertoire Documents"
hopper "Ouvre l'application Calculatrice"

# Questions
hopper "Quelle est la capitale de la France?"
hopper "Explique-moi le machine learning"

# Emails (Phase 2)
hopper "Lis mes nouveaux emails importants"

# IoT (Phase 2)
hopper "Allume les lumiÃ¨res du salon"
```

### API REST

```bash
# Envoyer une commande via API
curl -X POST http://localhost:5000/command \
  -H "Content-Type: application/json" \
  -d '{"text": "Bonjour HOPPER", "user_id": "demo"}'

# Consulter le contexte
curl http://localhost:5000/context/demo

# VÃ©rifier les capacitÃ©s
curl http://localhost:5000/api/v1/capabilities
```

## ğŸ“Š Performances

### MatÃ©riel RecommandÃ©

**Configuration TestÃ©e (MacBook Pro M3 Max):**
- CPU: 14 cÅ“urs (10 performance + 4 efficiency)
- GPU: 30 cÅ“urs
- RAM: 36 Go unifiÃ©e
- Neural Engine: 16 cÅ“urs

**Performances attendues:**
- InfÃ©rence LLM (13B): ~20-30 tokens/seconde
- Reconnaissance vocale: <1 seconde (Whisper medium)
- SynthÃ¨se vocale: temps rÃ©el
- Latence totale commande vocale: 2-4 secondes

## ğŸ—“ï¸ Feuille de Route

### Phase 1: Infrastructure de Base (Mois 1-2) âœ… EN COURS

- [x] Architecture microservices Docker
- [x] Orchestrateur central avec routage basique
- [x] Module d'exÃ©cution systÃ¨me en C
- [x] IntÃ©gration LLM avec mode simulation
- [ ] CLI fonctionnel avec mode interactif
- [ ] Tests d'intÃ©gration bout-en-bout

### Phase 2: IntÃ©grations Externes (Mois 3-4)

- [ ] Module STT (Whisper) opÃ©rationnel
- [ ] Module TTS avec voix franÃ§aise
- [ ] Connecteur email (IMAP/SMTP)
- [ ] Connecteur calendrier
- [ ] Connecteur IoT de base
- [ ] Interface vocale complÃ¨te

### Phase 3: Intelligence et Apprentissage (Mois 5-6)

- [ ] Base de connaissances vectorielle (FAISS)
- [ ] Retrieval Augmented Generation
- [ ] Fine-tuning local automatisÃ©
- [ ] Apprentissage par renforcement basique
- [ ] SystÃ¨me de feedback utilisateur
- [ ] Suggestions proactives

### Phase 4: SÃ©curitÃ© et Autonomie (Mois 7-8)

- [ ] Module d'authentification vocale
- [ ] Reconnaissance faciale
- [ ] Chiffrement des donnÃ©es sensibles
- [ ] Mode hors-ligne complet
- [ ] Gestion multi-utilisateurs
- [ ] RÃ¨gles de sÃ©curitÃ© configurables

### Phase 5: Optimisations (Mois 9-12)

- [ ] Optimisation C++ du moteur LLM
- [ ] Quantization avancÃ©e (int4)
- [ ] Cache intelligent des rÃ©ponses
- [ ] Apprentissage continu en arriÃ¨re-plan
- [ ] Interface graphique (dashboard)
- [ ] Application mobile companion

## ğŸ› ï¸ DÃ©veloppement

### Structure du Projet

```
HOPPER/
â”œâ”€â”€ docker/                 # Dockerfiles de chaque service
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ orchestrator/      # Orchestrateur central (Python)
â”‚   â”œâ”€â”€ llm_engine/        # Moteur LLM (Python/C++)
â”‚   â”œâ”€â”€ system_executor/   # ExÃ©cution systÃ¨me (C)
â”‚   â”œâ”€â”€ stt/              # Speech-to-Text (Python)
â”‚   â”œâ”€â”€ tts/              # Text-to-Speech (Python)
â”‚   â”œâ”€â”€ auth/             # Authentification (Python)
â”‚   â””â”€â”€ connectors/       # Connecteurs externes (Python)
â”œâ”€â”€ config/               # Fichiers de configuration
â”œâ”€â”€ data/                 # DonnÃ©es et modÃ¨les
â”œâ”€â”€ docs/                 # Documentation
â”œâ”€â”€ tests/                # Tests unitaires et d'intÃ©gration
â”œâ”€â”€ docker-compose.yml    # Orchestration des services
â””â”€â”€ hopper-cli.py        # Interface CLI

```

### Lancer en Mode DÃ©veloppement

```bash
# Rebuild et dÃ©marrage
docker-compose up --build

# Voir les logs d'un service
docker-compose logs -f orchestrator

# RedÃ©marrer un service
docker-compose restart llm

# ArrÃªter tous les services
docker-compose down
```

### Tests

```bash
# Tests unitaires
python -m pytest tests/

# Test d'un service spÃ©cifique
docker-compose exec orchestrator python -m pytest

# Tests d'intÃ©gration
./tests/integration_test.sh
```

## ğŸ”’ SÃ©curitÃ© et ConfidentialitÃ©

- **100% Local**: Aucune donnÃ©e envoyÃ©e au cloud
- **Chiffrement**: DonnÃ©es sensibles chiffrÃ©es au repos
- **Authentification**: Reconnaissance vocale/faciale
- **Isolation**: Chaque service dans son conteneur
- **Logs auditables**: TraÃ§abilitÃ© complÃ¨te des actions
- **Mode hors-ligne**: Fonctionnement sans Internet

## ğŸ“š Documentation

- [Guide d'Architecture](docs/ARCHITECTURE.md)
- [API Reference](docs/API.md)
- [Guide du DÃ©veloppeur](docs/DEVELOPMENT.md)
- [Foire Aux Questions](docs/FAQ.md)

## ğŸ¤ Contribution

Ce projet est actuellement en dÃ©veloppement actif. Les contributions sont les bienvenues!

## ğŸ“„ Licence

MIT License - voir le fichier [LICENSE](LICENSE)

## ğŸ™ Remerciements

- OpenAI Whisper pour la reconnaissance vocale
- Meta AI pour LLaMA
- llama.cpp pour l'optimisation d'infÃ©rence
- La communautÃ© open-source

## ğŸ“ Contact

- **Auteur**: jilani-BLK
- **Projet**: H.O.P.P.E.R
- **Repository**: [GitHub](https://github.com/jilani-BLK/H.O.P.P.E.R-Human-Operational-Predictive-Personal-Enhanced-Reactor)

---

**Note**: HOPPER est actuellement en Phase 1 (Alpha). De nombreuses fonctionnalitÃ©s sont en dÃ©veloppement actif.
