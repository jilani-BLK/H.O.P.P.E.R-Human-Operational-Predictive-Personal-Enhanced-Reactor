"""
LlmAgent - Pipeline ReAct complet
Thought ‚Üí Act ‚Üí Observe ‚Üí Answer avec planification via LLM
"""

import json
import asyncio
from typing import Dict, Any, List, Optional
from loguru import logger
import aiohttp

from core.models import (
    SystemPlan,
    ToolCall,
    ToolSummary,
    ToolStatus,
    RiskLevel,
    LlmPlanSchema
)
from core.prompt_assembler import PromptAssembler


class LlmAgent:
    """
    Agent LLM avec pipeline ReAct complet
    G√©n√®re des plans d'action structur√©s et g√®re l'ex√©cution
    """
    
    def __init__(
        self,
        llm_service_url: str,
        prompt_assembler: PromptAssembler,
        tool_executor=None,
        permission_manager=None
    ):
        self.llm_service_url = llm_service_url
        self.prompt_assembler = prompt_assembler
        self.tool_executor = tool_executor
        self.permission_manager = permission_manager
        
        # Configuration LLM
        self.default_params = {
            "max_tokens": 1024,
            "temperature": 0.7,
            "top_p": 0.9,
            "stop": ["</s>", "USER:", "ASSISTANT:"]
        }
    
    async def process(
        self,
        user_input: str,
        user_id: str = "default",
        session_id: str = ""
    ) -> Dict[str, Any]:
        """
        Pipeline ReAct complet:
        1. THOUGHT: Assembler prompt avec contexte
        2. ACT: LLM g√©n√®re SystemPlan
        3. OBSERVE: Ex√©cuter les tools et collecter r√©sultats
        4. ANSWER: Reformuler avec les r√©sultats
        
        Args:
            user_input: Entr√©e utilisateur
            user_id: ID utilisateur
            session_id: ID session
            
        Returns:
            R√©ponse structur√©e avec plan et r√©sultats
        """
        
        logger.info(f"üß† ReAct Pipeline - Input: '{user_input[:50]}...'")
        
        try:
            # ==================== THOUGHT ====================
            logger.debug("Step 1: THOUGHT - Assemblage contexte")
            prompt_data = self.prompt_assembler.assemble_prompt(
                user_input=user_input,
                user_id=user_id,
                session_id=session_id
            )
            
            # ==================== ACT (Plan) ====================
            logger.debug("Step 2: ACT - G√©n√©ration plan LLM")
            system_plan = await self._generate_plan(prompt_data)
            
            if not system_plan:
                # Fallback si √©chec LLM
                return self.prompt_assembler.create_fallback_response(
                    error="LLM g√©n√©ration failed",
                    user_input=user_input
                )
            
            # ==================== OBSERVE (Execute) ====================
            logger.debug(f"Step 3: OBSERVE - Ex√©cution {len(system_plan.tools)} outils")
            tool_summary = await self._execute_tools(
                system_plan.tools,
                user_id=user_id,
                session_id=session_id
            )
            
            # ==================== ANSWER (Reformulate) ====================
            logger.debug("Step 4: ANSWER - Reformulation avec r√©sultats")
            final_response = await self._reformulate_with_results(
                original_input=user_input,
                system_plan=system_plan,
                tool_summary=tool_summary,
                user_id=user_id
            )
            
            logger.success(f"‚úÖ ReAct Pipeline completed - {tool_summary.tools_executed} outils ex√©cut√©s")
            
            return final_response
            
        except Exception as e:
            logger.error(f"‚ùå ReAct Pipeline error: {e}")
            return self.prompt_assembler.create_fallback_response(
                error=str(e),
                user_input=user_input
            )
    
    async def _generate_plan(
        self,
        prompt_data: Dict[str, Any]
    ) -> Optional[SystemPlan]:
        """
        G√©n√®re un SystemPlan via LLM (function calling)
        
        Args:
            prompt_data: Donn√©es assembl√©es par PromptAssembler
            
        Returns:
            SystemPlan ou None si √©chec
        """
        
        try:
            # Construire le prompt complet
            full_prompt = self._build_full_prompt(prompt_data)
            
            # Appel au service LLM
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.llm_service_url}/generate",
                    json={
                        "prompt": full_prompt,
                        **self.default_params,
                        "response_format": "json"  # Demander JSON structur√©
                    },
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status != 200:
                        logger.error(f"LLM service error: {response.status}")
                        return None
                    
                    result = await response.json()
                    llm_text = result.get('text', '')
                    
                    # Parser la r√©ponse JSON du LLM
                    return self._parse_llm_response(llm_text)
        
        except asyncio.TimeoutError:
            logger.error("LLM timeout")
            return None
        except Exception as e:
            logger.error(f"LLM generation error: {e}")
            return None
    
    def _build_full_prompt(self, prompt_data: Dict[str, Any]) -> str:
        """Construit le prompt complet pour le LLM"""
        
        parts = []
        
        # System prompt
        parts.append(prompt_data['system_prompt'])
        parts.append("\n=== CONVERSATION ===")
        
        # Messages historiques
        for msg in prompt_data['messages']:
            role = msg['role'].upper()
            content = msg['content']
            parts.append(f"{role}: {content}")
        
        # Instruction finale
        parts.append("\nASSISTANT: ")
        
        return "\n".join(parts)
    
    def _parse_llm_response(self, llm_text: str) -> Optional[SystemPlan]:
        """
        Parse la r√©ponse JSON du LLM en SystemPlan
        
        Args:
            llm_text: Texte brut du LLM
            
        Returns:
            SystemPlan valid√© ou None
        """
        
        try:
            # Extraire JSON (le LLM peut ajouter du texte avant/apr√®s)
            json_start = llm_text.find('{')
            
            if json_start == -1:
                logger.warning("Pas de JSON trouv√© dans r√©ponse LLM")
                return None
            
            # Parser de mani√®re progressive pour g√©rer les multi-objets
            decoder = json.JSONDecoder()
            json_str = llm_text[json_start:]
            llm_data, idx = decoder.raw_decode(json_str)
            
            # Log si du texte suppl√©mentaire existe
            remaining = json_str[idx:].strip()
            if remaining:
                logger.debug(f"Texte ignor√© apr√®s JSON: {remaining[:100]}...")
            
            # Valider avec Pydantic
            plan_schema = LlmPlanSchema(**llm_data)
            
            # Convertir en SystemPlan
            system_plan = self._schema_to_system_plan(plan_schema)
            
            logger.debug(f"‚úÖ Plan pars√©: intent={system_plan.intent}, {len(system_plan.tools)} outils")
            
            return system_plan
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parse error: {e}")
            logger.debug(f"LLM text: {llm_text[:200]}...")
            return None
        except Exception as e:
            logger.error(f"Plan parsing error: {e}")
            return None
    
    def _schema_to_system_plan(self, schema: LlmPlanSchema) -> SystemPlan:
        """Convertit LlmPlanSchema en SystemPlan"""
        
        # Convertir actions en ToolCalls
        tool_calls = []
        for action in schema.actions:
            tool_call = ToolCall(
                tool_name=action.get('tool', 'unknown'),
                action=action.get('action', 'unknown'),
                parameters=action.get('params', {}),
                risk_level=self._assess_risk_level(action),
                narration=action.get('narration')
            )
            tool_calls.append(tool_call)
        
        return SystemPlan(
            intent=schema.intent,
            confidence=schema.confidence,
            tools=tool_calls,
            user_message=schema.response,
            reasoning=schema.reasoning,
            requires_more_info=schema.needs_more_info,
            suggested_followup=schema.followup_question
        )
    
    def _assess_risk_level(self, action: Dict[str, Any]) -> RiskLevel:
        """√âvalue le niveau de risque d'une action"""
        
        tool = action.get('tool', '')
        action_type = action.get('action', '')
        
        # R√®gles heuristiques
        if 'delete' in action_type or 'remove' in action_type:
            return RiskLevel.MEDIUM
        
        if 'execute_command' in action_type or 'sudo' in str(action.get('params', {})):
            return RiskLevel.HIGH
        
        if tool in ['llm_knowledge', 'tts']:
            return RiskLevel.SAFE
        
        if 'email' in tool and 'send' in action_type:
            return RiskLevel.MEDIUM
        
        return RiskLevel.LOW
    
    async def _execute_tools(
        self,
        tools: List[ToolCall],
        user_id: str,
        session_id: str
    ) -> ToolSummary:
        """
        Ex√©cute s√©quentiellement les tools avec v√©rification permissions
        
        Args:
            tools: Liste de ToolCall √† ex√©cuter
            user_id: ID utilisateur
            session_id: ID session
            
        Returns:
            ToolSummary avec r√©sultats
        """
        
        summary = ToolSummary(
            tools_executed=0,
            tools_succeeded=0,
            tools_failed=0
        )
        
        for tool_call in tools:
            logger.debug(f"Ex√©cution: {tool_call.tool_name}.{tool_call.action}")
            
            try:
                # V√©rifier permissions
                if self.permission_manager:
                    allowed = await self._check_permissions(
                        tool_call=tool_call,
                        user_id=user_id
                    )
                    
                    if not allowed:
                        tool_call.status = ToolStatus.BLOCKED
                        tool_call.error = "Permission refus√©e"
                        summary.add_tool_result(tool_call)
                        logger.warning(f"‚ùå {tool_call.tool_name}.{tool_call.action} - Permission refus√©e")
                        continue
                
                # Ex√©cuter l'outil
                if self.tool_executor:
                    result = await self.tool_executor.execute(tool_call)
                    
                    tool_call.status = ToolStatus.SUCCESS if result.get('success') else ToolStatus.FAILED
                    tool_call.result = result
                    tool_call.error = result.get('error')
                else:
                    # Simulation si pas d'executor
                    tool_call.status = ToolStatus.SUCCESS
                    tool_call.result = {"simulated": True}
                
                summary.add_tool_result(tool_call)
                
                logger.debug(f"‚úÖ {tool_call.tool_name}.{tool_call.action} - {tool_call.status}")
                
            except Exception as e:
                tool_call.status = ToolStatus.FAILED
                tool_call.error = str(e)
                summary.add_tool_result(tool_call)
                logger.error(f"‚ùå {tool_call.tool_name}.{tool_call.action} - {e}")
        
        return summary
    
    async def _check_permissions(
        self,
        tool_call: ToolCall,
        user_id: str
    ) -> bool:
        """
        V√©rifie les permissions pour un tool call
        
        Args:
            tool_call: Tool √† v√©rifier
            user_id: ID utilisateur
            
        Returns:
            True si autoris√©
        """
        
        try:
            # Demander au permission_manager
            result = await self.permission_manager.check(
                user_id=user_id,
                tool_name=tool_call.tool_name,
                action=tool_call.action,
                risk_level=tool_call.risk_level
            )
            
            return result.get('allowed', False)
            
        except Exception as e:
            logger.error(f"Permission check error: {e}")
            # Fail-safe: refuser par d√©faut
            return False
    
    async def _reformulate_with_results(
        self,
        original_input: str,
        system_plan: SystemPlan,
        tool_summary: ToolSummary,
        user_id: str
    ) -> Dict[str, Any]:
        """
        Reformule la r√©ponse finale avec les r√©sultats des outils (ReAct Answer)
        
        Args:
            original_input: Entr√©e utilisateur originale
            system_plan: Plan initial
            tool_summary: R√©sultats ex√©cution
            user_id: ID utilisateur
            
        Returns:
            R√©ponse finale structur√©e
        """
        
        # Si aucun outil ex√©cut√©, retourner le message original du plan
        if tool_summary.tools_executed == 0:
            return {
                "success": True,
                "message": system_plan.user_message,
                "data": {
                    "intent": system_plan.intent,
                    "confidence": system_plan.confidence
                },
                "actions_taken": []
            }
        
        # Cr√©er un prompt de reformulation avec observations
        replan_prompt = self.prompt_assembler.create_replan_prompt(
            original_input=original_input,
            tool_summary=tool_summary,
            user_id=user_id
        )
        
        # G√©n√©rer r√©ponse finale
        final_plan = await self._generate_plan(replan_prompt)
        
        if final_plan:
            final_message = final_plan.user_message
        else:
            # Fallback: construire message manuel
            final_message = self._build_fallback_message(system_plan, tool_summary)
        
        return {
            "success": tool_summary.tools_failed == 0,
            "message": final_message,
            "data": {
                "intent": system_plan.intent,
                "confidence": system_plan.confidence,
                "tools_executed": tool_summary.tools_executed,
                "tools_succeeded": tool_summary.tools_succeeded,
                "tools_failed": tool_summary.tools_failed,
                "results": tool_summary.results,
                "errors": tool_summary.errors
            },
            "actions_taken": [
                f"{t.tool_name}.{t.action}" for t in system_plan.tools
            ]
        }
    
    def _build_fallback_message(
        self,
        plan: SystemPlan,
        summary: ToolSummary
    ) -> str:
        """Construit un message de fallback si reformulation √©choue"""
        
        if summary.tools_succeeded == summary.tools_executed:
            return f"‚úÖ J'ai ex√©cut√© {summary.tools_executed} action(s) avec succ√®s."
        
        elif summary.tools_failed == summary.tools_executed:
            return f"‚ùå Les {summary.tools_failed} action(s) ont √©chou√©: {', '.join(summary.errors)}"
        
        else:
            return f"‚ö†Ô∏è {summary.tools_succeeded}/{summary.tools_executed} actions r√©ussies. Erreurs: {', '.join(summary.errors)}"


# ==================== EXPORT ====================

__all__ = ['LlmAgent']
