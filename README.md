# HOPPER - Human Operational Predictive Personal Enhanced Reactor

![Version](https://img.shields.io/badge/version-0.1.0--alpha-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Platform](https://img.shields.io/badge/platform-macOS%20M1%2FM2%2FM3-lightgrey)

> # H.O.P.P.E.R - Human Operational Predictive Personal Enhanced Reactor

**Assistant personnel intelligent fonctionnant 100% en local**  
DÃ©veloppÃ© en Python et C | Phase 2 complÃ©tÃ©e et optimisÃ©e âœ…

[![Phase 1](https://img.shields.io/badge/Phase%201-100%25%20Complete-success)](docs/PHASE1_FINAL_ANALYSIS.md)
[![Phase 2](https://img.shields.io/badge/Phase%202-95%25%20Complete-success)](PHASE2_SUCCESS.md)
[![Tests](https://img.shields.io/badge/Tests-53%2F53%20Passed-success)](tests/)
[![Code](https://img.shields.io/badge/Code-2453%20lines-blue)](#)

---

## ğŸ¯ Statut Actuel

**Version**: Phase 2 validÃ©e + Architecture Hybride (4 Novembre 2025)

| FonctionnalitÃ© | Status | Performance |
|---------------|--------|-------------|
| **Phase 2 Conversationnelle** | âœ… **VALIDÃ‰E 75%** | Taux rÃ©ussite tests |
| Architecture 5 services | âœ… 100% | Latence <1s |
| LLM (llama3.2 2GB) | âœ… OpÃ©rationnel | 810ms moyenne |
| Dispatcher Hybride | âœ… Intelligent | Routing systÃ¨me+LLM |
| Conversation multi-tour | âœ… Fonctionnel | 10 messages historique |
| RAG (Knowledge Base) | âœ… ChargÃ©e | 25 documents FAISS |
| CLI v2 Interactif | âœ… 100% | REPL + single-command |
| Mode offline | âœ… 100% | Ollama local v0.12.6 |
| Tests automatisÃ©s | âœ… 15/20 validÃ©s | 75% succÃ¨s |

### ğŸ‰ Phase 2 ValidÃ©e (Nouveau)

HOPPER peut maintenant **converser en franÃ§ais de maniÃ¨re naturelle** et **maintenir le contexte** sur plusieurs Ã©changes.

**Architecture Hybride** (SystÃ¨me + LLM):
- ğŸ¯ **Dispatcher Intelligent**: Routage automatique commandes systÃ¨me vs conversations
- ğŸ§  **LLM Local**: llama3.2 (2GB) via Ollama v0.12.6, 100% offline
- ğŸ’¬ **Conversations Multi-tour**: Historique 10 messages, contexte maintenu
- ï¿½ **Knowledge Base**: 25 documents FAISS, RAG ready
- ğŸ–¥ï¸ **CLI v2**: Mode interactif REPL + single-command

ğŸ“˜ **Documentation**: [`PHASE2_VALIDATION.md`](PHASE2_VALIDATION.md) | ğŸš€ **SuccÃ¨s**: [`PHASE2_SUCCESS.md`](PHASE2_SUCCESS.md) | ğŸ§ª **Tests**: [`scripts/test/validate_phase2.py`](scripts/test/validate_phase2.py)

ğŸ“Š [**Rapport Performance Complet**](PERFORMANCE_ANALYSIS.md) | ğŸ“ˆ [**RÃ©sultats Optimisation**](OPTIMIZATION_RESULTS.md) | ğŸ“‹ [**Rapport Final**](FINAL_REPORT.md)

HOPPER est un assistant IA personnel conÃ§u pour apprendre de lui-mÃªme, traiter des tÃ¢ches en temps rÃ©el et s'intÃ©grer avec de multiples systÃ¨mes - le tout sur votre machine, sans dÃ©pendance cloud.

## CaractÃ©ristiques Principales

- **Intelligence Locale**: ModÃ¨le de langage puissant (LLaMA/Mistral) tournant sur Mac M3 Max
- **Apprentissage Autonome**: Fine-tuning local et apprentissage par renforcement
- **100% PrivÃ©**: Aucune donnÃ©e envoyÃ©e au cloud, tout reste sur votre machine
- **Performances Optimales**: Architecture C/C++/Python pour vitesse maximale
- **Interface Vocale**: Reconnaissance (Whisper) et synthÃ¨se vocale naturelle
- **SÃ©curitÃ©**: Authentification vocale/faciale intÃ©grÃ©e
- **Modulaire**: Architecture microservices Docker extensible

## DÃ©marrage Rapide

```bash
# 1. Cloner le projet
git clone https://github.com/jilani-BLK/H.O.P.P.E.R-Human-Operational-Predictive-Personal-Enhanced-Reactor.git
cd HOPPER

# 2. Installation automatique
chmod +x install.sh
./install.sh

# 3. Tester
python3 hopper-cli.py -i
```

**Guide dÃ©taillÃ©**: [docs/QUICKSTART.md](docs/QUICKSTART.md)

## Exemples d'Utilisation

```bash
# Mode interactif conversationnel (NOUVEAU Phase 2)
python3 hopper_cli_v2.py

hopper> Bonjour, qui es-tu ?
ğŸ¤– HOPPER: Je suis HOPPER, votre assistant personnel intelligent et local...
â±ï¸ 2.1s | 142 tokens

hopper> Que peux-tu faire ?
ğŸ¤– HOPPER: Je peux exÃ©cuter des commandes systÃ¨me et rÃ©pondre Ã  vos questions...
â±ï¸ 1.8s | 98 tokens

# Mode single-command (conversations)
python3 hopper_cli_v2.py "C'est quoi un LLM ?"

# Commandes systÃ¨me (Phase 1)
python3 hopper_cli_v2.py "liste les fichiers de /tmp"
python3 hopper_cli_v2.py "crÃ©e un fichier notes.txt"
python3 hopper_cli_v2.py "donne moi la date"

# API REST
curl -X POST http://localhost:5050/api/v1/command \
  -d '{"command":"Qui es-tu ?"}'
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         INTERFACES UTILISATEUR          â”‚
â”‚    CLI â”‚ Voix â”‚ API REST â”‚ Web GUI     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ORCHESTRATEUR CENTRAL              â”‚
â”‚  (Analyse, Routage, Contexte, DÃ©cision) â”‚
â””â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚     â”‚     â”‚     â”‚     â”‚     â”‚
  â–¼     â–¼     â–¼     â–¼     â–¼     â–¼
â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”€â”
â”‚LLMâ”‚ â”‚SYSâ”‚ â”‚STTâ”‚ â”‚TTSâ”‚ â”‚AUTâ”‚ â”‚CONNâ”‚
â”‚C++â”‚ â”‚ C â”‚ â”‚Py â”‚ â”‚Py â”‚ â”‚Py â”‚ â”‚ Py â”‚
â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜
```

**Services**:
- **Orchestrateur** (Python): Cerveau central coordonnant tous les services
- **LLM Engine** (C++ llama.cpp): ModÃ¨le de langage optimisÃ© pour Apple Silicon
- **System Executor** (C): Actions systÃ¨me haute performance
- **STT** (Whisper): Reconnaissance vocale multilingue
- **TTS**: SynthÃ¨se vocale naturelle
- **Auth**: Authentification vocale/faciale
- **Connectors**: IntÃ©grations (email, IoT, calendrier...)

**Architecture dÃ©taillÃ©e**: [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md)

## Performances

**Configuration TestÃ©e** (MacBook Pro M3 Max):
- CPU: 14 cÅ“urs | GPU: 30 cÅ“urs | RAM: 36 Go
- **LLM (13B)**: 20-30 tokens/sec
- **Whisper**: <1 sec transcription
- **Latence totale** (voix â†’ rÃ©ponse): 2-4 sec

## Roadmap

- [x] **Phase 1** (Mois 1-2): Infrastructure microservices âœ…
- [ ] **Phase 2** (Mois 3-4): IntÃ©grations (email, voix, IoT)
- [ ] **Phase 3** (Mois 5-6): Apprentissage et RAG
- [ ] **Phase 4** (Mois 7-8): SÃ©curitÃ© avancÃ©e
- [ ] **Phase 5** (Mois 9-12): Optimisations et GUI

[Voir la feuille de route complÃ¨te](docs/README.md)

## Documentation

- [Guide Complet](docs/README.md)
- [DÃ©marrage Rapide](docs/QUICKSTART.md)
- [Architecture](docs/ARCHITECTURE.md)

## Technologies

**Langages**: Python 3.11, C (C11), C++ (via bindings)

**Frameworks**:
- FastAPI, aiohttp (APIs)
- llama.cpp (infÃ©rence LLM)
- OpenAI Whisper (STT)
- Docker & Docker Compose

**IA/ML**:
- LLaMA 2 / Mistral (modÃ¨les)
- FAISS (base vectorielle)
- Sentence-Transformers (embeddings)

## Contribution

Les contributions sont bienvenues! Ce projet est en dÃ©veloppement actif (Phase 1).

## Licence

MIT License - Voir [LICENSE](LICENSE)

## Contact

- **Auteur**: jilani-BLK
- **GitHub**: [H.O.P.P.E.R](https://github.com/jilani-BLK/H.O.P.P.E.R-Human-Operational-Predictive-Personal-Enhanced-Reactor)

---

**Note**: HOPPER est actuellement en **Phase 1 (Alpha)**. L'architecture de base est fonctionnelle, les fonctionnalitÃ©s avancÃ©es sont en dÃ©veloppement.
