services:
  # Orchestrateur Central (Python)
  orchestrator:
    build:
      context: .
      dockerfile: docker/orchestrator.Dockerfile
    container_name: hopper-orchestrator
    ports:
      - "${ORCHESTRATOR_PORT:-5050}:5050"
    volumes:
      # Mount orchestrator code
      - ./src/orchestrator:/app
      # Mount dependencies for imports
      - ./src/filesystem:/filesystem
      - ./src/__init__.py:/src/__init__.py
      # Mount config and data
      - ./config:/config
      - ./data:/data
    environment:
      - ORCHESTRATOR_PORT=${ORCHESTRATOR_PORT:-5050}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app/..
    env_file:
      - .env
    depends_on:
      - llm
      - system_executor
      - connectors
      - whisper
      - tts_piper
    networks:
      - hopper_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5050/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Moteur LLM (C++ avec llama.cpp)
  llm:
    build:
      context: .
      dockerfile: docker/llm.Dockerfile
    container_name: hopper-llm
    ports:
      - "${LLM_SERVICE_PORT:-5001}:5001"
    volumes:
      - ./src/llm_engine:/app
      - ./data/models:/models:ro
      - ./data/vector_store:/data/vector_store
      - ./config:/config:ro
    environment:
      - LLM_SERVICE_PORT=5001
      - OLLAMA_HOST=http://host.docker.internal:11434
      - OLLAMA_MODEL=llama3.2
      - LLM_CONTEXT_SIZE=4096
      - KB_PERSIST_PATH=/data/vector_store
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
    env_file:
      - .env
    depends_on:
      - qdrant
    networks:
      - hopper_network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Module d'exécution système (C)
  system_executor:
    build:
      context: .
      dockerfile: docker/system_executor_python.Dockerfile
    container_name: hopper-system-executor
    ports:
      - "${SYSTEM_EXECUTOR_PORT:-5002}:5002"
    volumes:
      - ./config/command_whitelist.yaml:/app/config/command_whitelist.yaml:ro
    environment:
      - SYSTEM_EXECUTOR_PORT=5002
      - SYSTEM_EXECUTOR_WHITELIST=/app/config/command_whitelist.yaml
    env_file:
      - .env
    networks:
      - hopper_network
    restart: unless-stopped
    privileged: false

  # Module d'authentification
  auth:
    build:
      context: .
      dockerfile: docker/auth.Dockerfile
    container_name: hopper-auth
    ports:
      - "${AUTH_SERVICE_PORT:-5005}:5005"
    volumes:
      - ./src/auth:/app
      - ./data/auth:/data
    environment:
      - AUTH_SERVICE_PORT=5005
      - CONFIDENCE_THRESHOLD=${AUTH_CONFIDENCE_THRESHOLD:-0.85}
    env_file:
      - .env
    networks:
      - hopper_network
    restart: unless-stopped

  # Connecteurs (groupés pour Phase 1)
  connectors:
    build:
      context: .
      dockerfile: docker/connectors.Dockerfile
    container_name: hopper-connectors
    ports:
      - "5006:5006"
    volumes:
      - ./src/connectors:/app
      - ./config:/config
      - ./data/connectors:/data
    environment:
      - CONNECTOR_SERVICE_PORT=5006
    env_file:
      - .env
    networks:
      - hopper_network
    restart: unless-stopped

  # ============================================
  # PHASE 3 - Production Voice & Email Services
  # ============================================

  # Service 4: Whisper STT (Speech-to-Text) - Version Simple
  whisper:
    image: hopper-whisper:latest
    container_name: hopper_whisper
    ports:
      - "5003:5003"
    volumes:
      - ./data/audio_samples:/app/audio_samples:ro
    environment:
      - MODEL_SIZE=base
      - LANGUAGE=fr
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - hopper_network

  # Piper TTS - Production Text-to-Speech
  tts_piper:
    build:
      context: .
      dockerfile: docker/tts_piper.Dockerfile
    container_name: hopper-tts-piper
    ports:
      - "5004:5004"
    volumes:
      - piper_models:/app/models
    environment:
      - TTS_SERVICE_PORT=5004
      - PIPER_VOICE=fr_FR-siwis-medium
      - SAMPLE_RATE=22050
    networks:
      - hopper_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5004/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Voice Authentication - Speaker Verification
  auth_voice:
    build:
      context: .
      dockerfile: docker/auth_voice.Dockerfile
    container_name: hopper-auth-voice
    ports:
      - "5007:5007"
    volumes:
      - voice_profiles:/app/profiles
      - ./src/voice:/app/src/voice
    environment:
      - AUTH_VOICE_PORT=5007
      - SPEAKER_MODEL=speechbrain/spkrec-ecapa-voxceleb
      - SIMILARITY_THRESHOLD=0.75
    networks:
      - hopper_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5007/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 3G

  # Email Connector - DISABLED FOR NOW
  # Uncomment when ready to use email features
  # email:
  #   build:
  #     context: .
  #     dockerfile: docker/email.Dockerfile
  #   container_name: hopper-email
  #   ports:
  #     - "5008:5008"
  #   volumes:
  #     - email_cache:/app/cache
  #     - ./src/connectors/email:/app/email
  #   environment:
  #     - EMAIL_SERVICE_PORT=5008
  #     - CHECK_INTERVAL=${EMAIL_CHECK_INTERVAL:-60}
  #   env_file:
  #     - .env
  #     - .env.email  # Email credentials séparés
  #   networks:
  #     - hopper_network
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:5008/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 20s
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 512M
  #       reservations:
  #         memory: 256M

  # Qdrant - Vector Database (Phase 2 concrétisation)
  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: hopper-qdrant
    ports:
      - "6333:6333"   # REST API
      - "6334:6334"   # gRPC (optionnel)
    volumes:
      - qdrant_data:/qdrant/storage
    networks:
      - hopper_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # Neo4j - GraphRAG Database (Phase 3.5)
  neo4j:
    image: neo4j:5.15-community
    container_name: hopper-neo4j
    ports:
      - "7474:7474"   # HTTP Browser
      - "7687:7687"   # Bolt protocol
    environment:
      - NEO4J_AUTH=neo4j/hopper123
      - NEO4J_dbms_memory_pagecache_size=1G
      - NEO4J_dbms_memory_heap_initial__size=1G
      - NEO4J_dbms_memory_heap_max__size=2G
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    networks:
      - hopper_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "hopper123", "RETURN 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

networks:
  hopper_network:
    driver: bridge

volumes:
  # Phase 1 & 2
  models:
  vector_store:
  auth_data:
  qdrant_data:
  
  # Phase 3 - Voice & Email
  whisper_models:
    driver: local
  piper_models:
    driver: local
  voice_profiles:
    driver: local
  email_cache:
    driver: local
  
  # Phase 3.5 - GraphRAG
  neo4j_data:
  neo4j_logs:
