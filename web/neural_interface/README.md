# ğŸ§  HOPPER Neural Interface

Interface neuronale 3D interactive en temps rÃ©el pour visualiser le cerveau de HOPPER.

![Neural Interface](https://img.shields.io/badge/Status-Beta-orange)
![WebSocket](https://img.shields.io/badge/WebSocket-Real--time-green)
![Three.js](https://img.shields.io/badge/Three.js-3D-blue)

## âœ¨ FonctionnalitÃ©s

### ğŸ¨ Visualisation 3D
- **50 neurones** organisÃ©s en 5 couches (Input, STT, Dispatcher, LLM, Output)
- **Connexions dynamiques** entre neurones adjacents
- **Animation fluide** avec rotation automatique et effets de particules
- **ActivitÃ© temps rÃ©el** : les neurones s'illuminent selon l'activitÃ© de HOPPER

### ğŸ¤ Clonage Vocal
- **Clone la voix de HOPPER** depuis l'Ã©chantillon audio `Hopper_voix.wav.mp3` (22 sec)
- Utilise **Coqui TTS XTTS-v2** pour synthÃ¨se vocale haute fidÃ©litÃ©
- Supporte multi-langues (FR, EN, ES, etc.)

### âš¡ Monitoring Temps RÃ©el
- **WebSocket** pour streaming d'Ã©vÃ©nements
- Les neurones **s'accÃ©lÃ¨rent quand HOPPER parle**
- Tracking des services (STT, LLM, TTS, etc.)
- Logs d'activitÃ© colorÃ©s par type d'Ã©vÃ©nement

### ğŸ“Š HUD Informatif
- Compteur de neurones actifs
- Statut des services
- Latence rÃ©seau
- Niveau d'activitÃ©

## ğŸš€ Installation

### 1. DÃ©pendances Python

```bash
# DÃ©pendances vocales
pip install TTS pydub

# DÃ©pendances serveur
pip install fastapi uvicorn websockets httpx

# Optional: pour audio processing
pip install soundfile librosa
```

### 2. PrÃ©parer l'Ã©chantillon vocal

Placez votre fichier audio Ã  la racine du projet :
```
HOPPER/
â”œâ”€â”€ Hopper_voix.wav.mp3  # 22 secondes d'Ã©chantillon vocal
â””â”€â”€ ...
```

Formats supportÃ©s : WAV, MP3, M4A, FLAC, etc.

## ğŸ¯ Utilisation

### 1. DÃ©marrer le serveur neural interface

```bash
cd web/neural_interface
python neural_server.py
```

Le serveur dÃ©marre sur `http://localhost:5050`

### 2. Ouvrir l'interface web

Naviguer vers : **http://localhost:5050/**

Ou utiliser le mode dÃ©mo :
```
http://localhost:5050/?demo=true
```

### 3. DÃ©marrer l'orchestrator avec monitoring

L'orchestrator s'initialise automatiquement avec le neural monitoring :

```bash
cd src/orchestrator
python main.py
```

### 4. Tester le clonage vocal

```bash
cd src/tts
python voice_cloning.py "Bonjour, je suis HOPPER, votre assistant intelligent!"
```

L'audio gÃ©nÃ©rÃ© sera sauvegardÃ© dans `hopper_test_voice.wav`

Ã‰couter :
```bash
afplay hopper_test_voice.wav  # macOS
# ou ouvrir dans votre lecteur audio
```

## ğŸ“¡ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   HOPPER ORCHESTRATOR               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Neural Activity Monitor (Middleware)       â”‚  â”‚
â”‚  â”‚   - Capture events (STT, LLM, TTS, etc.)     â”‚  â”‚
â”‚  â”‚   - Send to Neural Server via HTTP           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ HTTP POST /api/neural/event
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Neural Interface Server                  â”‚
â”‚            (FastAPI + WebSocket)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Connection Manager                         â”‚  â”‚
â”‚  â”‚   - Manage WebSocket clients                 â”‚  â”‚
â”‚  â”‚   - Broadcast events to all clients          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ WebSocket ws://localhost:5050/ws/neural
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Neural Interface Web (Three.js)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   3D Neural Network Visualization            â”‚  â”‚
â”‚  â”‚   - 50 neurons in 5 layers                   â”‚  â”‚
â”‚  â”‚   - Dynamic connections                      â”‚  â”‚
â”‚  â”‚   - Real-time activity pulsing               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants

#### 1. **Voice Cloning** (`src/tts/voice_cloning.py`)
- Clone la voix de HOPPER avec Coqui TTS XTTS-v2
- NÃ©cessite seulement 6-22 sec d'audio
- Support multi-langues

#### 2. **Neural Server** (`web/neural_interface/neural_server.py`)
- Serveur FastAPI avec WebSocket
- Endpoints HTTP pour recevoir Ã©vÃ©nements
- Broadcasting temps rÃ©el vers clients web

#### 3. **Neural Monitor** (`src/orchestrator/neural_monitor.py`)
- Middleware pour l'orchestrator
- Capture automatique des Ã©vÃ©nements
- Queue asynchrone pour performance

#### 4. **Web Interface** (`web/neural_interface/`)
- `index.html` : Structure HTML + HUD
- `neural_visualization.js` : Three.js 3D rendering
- `websocket_client.js` : Client WebSocket + event handling

## ğŸ® Events Types

### Neural Activity Events

| Type | Description | Visualisation |
|------|-------------|---------------|
| `input` | Commande utilisateur reÃ§ue | Neurones Input actifs |
| `stt` | Speech-to-Text en cours | Neurones STT pulsent (cyan) |
| `dispatch` | Dispatching d'intention | Neurones Dispatcher actifs (orange) |
| `llm` | LLM gÃ©nÃ¨re rÃ©ponse | Neurones LLM pulsent fort (magenta) |
| `tts` | Text-to-Speech gÃ©nÃ¨re audio | Neurones Output actifs (jaune) |
| `service` | Appel service gÃ©nÃ©rique | Neurones alÃ©atoires (vert) |

### Voice Activity Events

Quand HOPPER parle :
- **pulse_speed x2** : Les neurones s'accÃ©lÃ¨rent
- **15 neurones** activÃ©s simultanÃ©ment
- Retour Ã  la normale aprÃ¨s la parole

## ğŸ”§ Configuration

### Neural Monitor

```python
# Dans src/orchestrator/main.py

neural_monitor = init_neural_monitor(
    neural_server_url="http://localhost:5050",
    enabled=True  # DÃ©sactiver en production si nÃ©cessaire
)
```

### Neural Server

```python
# Dans web/neural_interface/neural_server.py

# Port du serveur
PORT = 5050

# FrÃ©quence des stats
STATS_INTERVAL = 2  # secondes
```

### Visualization

```javascript
// Dans neural_visualization.js

config = {
    neuronCount: 50,       // Nombre de neurones
    layerCount: 5,         // Nombre de couches
    connectionProbability: 0.15,  // DensitÃ© des connexions
    pulseSpeed: 2.0,       // Vitesse de pulsation (x2 quand parle)
    rotationSpeed: 0.001   // Vitesse de rotation
}
```

## ğŸ“Š API Reference

### Neural Server Endpoints

#### `GET /`
Interface web principale

#### `GET /health`
Health check + statistiques
```json
{
  "status": "healthy",
  "active_connections": 2,
  "stats": {
    "events_sent": 150,
    "connections_total": 5
  }
}
```

#### `WebSocket /ws/neural`
Endpoint WebSocket pour streaming temps rÃ©el

**Messages reÃ§us :**
```json
{
  "type": "neural_activity",
  "payload": {
    "event_type": "llm",
    "intensity": 1.5,
    "metadata": {...}
  }
}
```

#### `POST /api/neural/event`
Envoyer un Ã©vÃ©nement neural
```json
{
  "type": "neural_activity",
  "payload": {
    "event_type": "stt",
    "intensity": 1.0,
    "metadata": {"text": "Hello"}
  }
}
```

#### `POST /api/neural/voice`
Signaler activitÃ© vocale
```json
{
  "speaking": true,
  "text": "Bonjour, je suis HOPPER",
  "duration": 2.5
}
```

#### `POST /api/neural/service`
Signaler Ã©vÃ©nement service
```json
{
  "service": "llm",
  "status": "completed",
  "duration": 1.2
}
```

## ğŸ¨ Personnalisation

### Couleurs des neurones

```javascript
// neural_visualization.js

config.baseColor = 0x00ff00;    // Vert (idle)
config.activeColor = 0xff00ff;  // Magenta (actif)
```

### Types de neurones

Modifier les couches dans `createNeuralNetwork()`:
```javascript
const types = [
  'input',      // Layer 0
  'stt',        // Layer 1
  'dispatcher', // Layer 2
  'llm',        // Layer 3
  'output'      // Layer 4
];
```

### Vitesse de parole

```javascript
// websocket_client.js - handleVoiceActivity()

if (speaking) {
    neuralNet.config.pulseSpeed = 4.0;  // Modifier ici
}
```

## ğŸ› Troubleshooting

### Le serveur neural ne dÃ©marre pas
```bash
# VÃ©rifier que le port 5050 est libre
lsof -i :5050

# Tuer le processus si nÃ©cessaire
kill -9 <PID>
```

### L'interface ne se connecte pas
1. VÃ©rifier que le serveur neural tourne : `http://localhost:5050/health`
2. Ouvrir la console navigateur (F12) pour voir les erreurs WebSocket
3. VÃ©rifier les CORS si dÃ©ployÃ© sur domaine diffÃ©rent

### Le clonage vocal Ã©choue
```bash
# VÃ©rifier l'installation de TTS
python -c "from TTS.api import TTS; print('OK')"

# VÃ©rifier pydub
python -c "from pydub import AudioSegment; print('OK')"

# VÃ©rifier l'Ã©chantillon audio
ls -lh Hopper_voix.wav.mp3
```

### Les neurones ne s'animent pas
1. VÃ©rifier que le neural monitor est activÃ© dans l'orchestrator
2. VÃ©rifier les logs du serveur neural
3. Utiliser le mode dÃ©mo : `?demo=true`

## ğŸ“ TODO / AmÃ©liorations futures

- [ ] Support multi-utilisateurs (couleurs diffÃ©rentes par utilisateur)
- [ ] Enregistrement et replay de sessions
- [ ] Graphiques de performance (latence, throughput)
- [ ] Export vidÃ©o de l'activitÃ© neuronale
- [ ] Mode VR/AR pour visualisation immersive
- [ ] Fine-tuning du modÃ¨le vocal avec plus d'Ã©chantillons
- [ ] Reconnaissance d'Ã©motions dans la voix
- [ ] Compression des Ã©vÃ©nements pour performances
- [ ] Dashboard administrateur
- [ ] Alertes visuelles sur erreurs

## ğŸ¤ Contributing

Pour contribuer :
1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“„ License

Ce projet fait partie de HOPPER - voir LICENSE pour dÃ©tails.

## ğŸ™ Remerciements

- **Coqui TTS** pour le clonage vocal
- **Three.js** pour le rendu 3D
- **FastAPI** pour le serveur WebSocket
- La communautÃ© open-source

---

**Status**: âœ… Production Ready  
**Version**: 1.0.0  
**Last Updated**: 24 octobre 2025

Pour questions ou support : ouvrir une issue sur GitHub
