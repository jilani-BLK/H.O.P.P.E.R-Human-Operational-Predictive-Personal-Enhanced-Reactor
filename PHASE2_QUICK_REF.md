# üéØ PHASE 2 - QUICK REFERENCE

## Statut : ‚úÖ VALID√âE (4 novembre 2025)

**Taux de r√©ussite :** 75% (15/20 tests) - Crit√®re ‚â•70% atteint

---

## üöÄ Lancer HOPPER Phase 2

### Mode Interactif (Recommand√©)
```bash
python3 hopper_cli_v2.py

hopper> Bonjour, qui es-tu ?
hopper> Que peux-tu faire ?
hopper> liste les fichiers de /tmp
hopper> exit
```

### Mode Single Command
```bash
# Conversation
python3 hopper_cli_v2.py "C'est quoi un LLM ?"

# Commande syst√®me
python3 hopper_cli_v2.py "liste les fichiers de /tmp"
```

### API REST
```bash
# Status
curl http://localhost:5050/api/v1/status

# Commande
curl -X POST http://localhost:5050/api/v1/command \
  -H "Content-Type: application/json" \
  -d '{"command": "Qui es-tu ?"}'
```

---

## ‚úÖ Fonctionnalit√©s Valid√©es

| Fonctionnalit√© | Statut | Performance |
|----------------|--------|-------------|
| Conversations fran√ßaises | ‚úÖ | 1529ms moyenne |
| Commandes syst√®me | ‚úÖ | 25ms moyenne |
| Routing hybride | ‚úÖ | 75% pr√©cision |
| Multi-tour (10 msgs) | ‚úÖ | Contexte maintenu |
| CLI v2 interactif | ‚úÖ | REPL op√©rationnel |
| Knowledge Base | ‚úÖ | 25 docs charg√©s |
| Mode offline | ‚úÖ | Ollama v0.12.6 |

---

## üìä Tests Automatis√©s

```bash
# Lancer validation Phase 2
python3 scripts/test/validate_phase2.py

# R√©sultats attendus
‚úÖ R√©ussis: 15/20 (75.0%)
‚è±Ô∏è Latence: moy=810ms
```

---

## üèóÔ∏è Services Docker

```bash
# Statut services
docker-compose ps

# Logs
docker-compose logs orchestrator
docker-compose logs llm

# Red√©marrer
docker-compose restart orchestrator
```

**Services actifs :**
- `orchestrator:5050` - Phase 2 (main_phase2.py)
- `llm:5001` - Ollama client + KB
- `system_executor:5002` - Commandes syst√®me

---

## üéØ LLM Configuration

**Mod√®le actif :** llama3.2:latest (2GB)  
**Ollama :** v0.12.6 sur localhost:11434  
**Contexte :** 4096 tokens  
**Performance :** 30-50 tokens/seconde

```bash
# V√©rifier Ollama
ollama list

# Tester mod√®le
ollama run llama3.2 "Bonjour"
```

---

## üìÅ Fichiers Principaux

### Code Source (Phase 2)
- `src/orchestrator/core/llm_dispatcher.py` - Routing intelligent
- `src/orchestrator/api/phase2_routes.py` - API hybride
- `src/orchestrator/main_phase2.py` - Orchestrateur
- `src/orchestrator/core/conversation_manager.py` - Historique
- `hopper_cli_v2.py` - CLI v2
- `scripts/test/validate_phase2.py` - Tests validation

### Documentation
- `PHASE2_VALIDATION.md` - R√©sultats tests
- `PHASE2_FINAL_REPORT.md` - Rapport complet
- `PHASE2_SUCCESS.md` - Documentation succ√®s
- `README.md` - Guide principal

---

## üêõ Troubleshooting

### Orchestrator ne d√©marre pas
```bash
docker-compose logs orchestrator
# V√©rifier variables env Ollama
```

### LLM ne r√©pond pas
```bash
# V√©rifier Ollama fonctionne
ollama list
ollama run llama3.2 "test"

# V√©rifier connexion Docker ‚Üí host
docker-compose exec orchestrator ping host.docker.internal
```

### CLI v2 erreurs
```bash
# V√©rifier orchestrator actif
curl http://localhost:5050/api/v1/status

# Logs d√©taill√©s
python3 hopper_cli_v2.py "test" --verbose
```

---

## üìà M√©triques

**Latence :**
- Syst√®me : 25ms moyenne
- Conversation : 1529ms moyenne
- Global : 810ms moyenne

**Taux de r√©ussite :**
- Syst√®me : 6/8 (75%)
- Conversation : 9/12 (75%)
- Total : 15/20 (75%)

**Tokens :**
- Prompt : ~150 tokens
- R√©ponse : 100-160 tokens
- Total : 250-310 tokens/√©change

---

## üöÄ Prochaines √âtapes

### Phase 3 Priorit√©s
1. **Am√©liorer routing** : 75% ‚Üí 90%+ pr√©cision
2. **Tester RAG** : D√©monstration Knowledge Base
3. **Optimiser performance** : <1s pour conversations courtes
4. **Impl√©menter "hopper learn"** : Commande apprentissage

---

## üìö Commandes Utiles

```bash
# Rebuild services
docker-compose build orchestrator llm
docker-compose up -d

# Tests complets
python3 scripts/test/validate_phase2.py

# Logs temps r√©el
docker-compose logs -f orchestrator

# Status complet
curl http://localhost:5050/api/v1/status | jq

# Conversation test
python3 hopper_cli_v2.py "Bonjour HOPPER"

# Commande syst√®me test
python3 hopper_cli_v2.py "liste /tmp"
```

---

## ‚úÖ Validation

**Phase 2 valid√©e le 4 novembre 2025**

- ‚úÖ 75% taux r√©ussite (‚â•70% requis)
- ‚úÖ 810ms latence (<5s requis)
- ‚úÖ 100% offline (Ollama local)
- ‚úÖ Conversations fran√ßaises naturelles
- ‚úÖ Multi-tour contextuel

**Pr√™t pour Phase 3** üöÄ

---

*HOPPER v2.0 - Quick Reference*
