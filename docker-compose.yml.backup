services:
  # Orchestrateur Central (Python)
  orchestrator:
    build:
      context: .
      dockerfile: docker/orchestrator.Dockerfile
    container_name: hopper-orchestrator
    ports:
      - "${ORCHESTRATOR_PORT:-8000}:8000"
    volumes:
      - ./src/orchestrator:/app
      - ./config:/config
      - ./data:/data
    environment:
      - ORCHESTRATOR_PORT=8000
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
    env_file:
      - .env
    depends_on:
      - llm
      - system_executor
    networks:
      - hopper-network
    restart: unless-stopped

  # Moteur LLM (C++ avec llama.cpp)
  llm:
    build:
      context: .
      dockerfile: docker/llm.Dockerfile
    container_name: hopper-llm
    ports:
      - "${LLM_SERVICE_PORT:-5001}:5001"
    volumes:
      - ./src/llm_engine:/app
      - ./data/models:/models:ro
      - ./data/vector_store:/data/vector_store
      - ./config:/config:ro
    environment:
      - LLM_SERVICE_PORT=5001
      - LLM_MODEL_PATH=${LLM_MODEL_PATH}
      - LLM_CONTEXT_SIZE=${LLM_CONTEXT_SIZE}
      - LLM_N_THREADS=${LLM_N_THREADS}
      - LLM_N_GPU_LAYERS=${LLM_N_GPU_LAYERS}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS}
      - KB_PERSIST_PATH=${KB_PERSIST_PATH}
      - KB_EMBEDDING_MODEL=${KB_EMBEDDING_MODEL}
    env_file:
      - .env
    networks:
      - hopper-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G

  # Module d'exécution système (C)
  system_executor:
    build:
      context: .
      dockerfile: docker/system_executor.Dockerfile
    container_name: hopper-system-executor
    ports:
      - "${SYSTEM_EXECUTOR_PORT:-5002}:5002"
    volumes:
      - /Users:/host_users:ro
    environment:
      - SYSTEM_EXECUTOR_PORT=5002
    env_file:
      - .env
    networks:
      - hopper-network
    restart: unless-stopped
    privileged: false

  # Module STT (Speech-to-Text)
  stt:
    build:
      context: .
      dockerfile: docker/stt.Dockerfile
    container_name: hopper-stt
    ports:
      - "${STT_SERVICE_PORT:-5003}:5003"
    volumes:
      - ./src/stt:/app
      - ./data/models:/models
    environment:
      - STT_SERVICE_PORT=5003
      - STT_MODEL=${STT_MODEL:-whisper-medium}
      - STT_LANGUAGE=${STT_LANGUAGE:-fr}
    env_file:
      - .env
    networks:
      - hopper-network
    restart: unless-stopped

  # Module TTS (Text-to-Speech)
  tts:
    build:
      context: .
      dockerfile: docker/tts.Dockerfile
    container_name: hopper-tts
    ports:
      - "${TTS_SERVICE_PORT:-5004}:5004"
    volumes:
      - ./src/tts:/app
      - ./data/models:/models
    environment:
      - TTS_SERVICE_PORT=5004
      - TTS_VOICE=${TTS_VOICE:-fr-FR}
    env_file:
      - .env
    networks:
      - hopper-network
    restart: unless-stopped

  # Module d'authentification
  auth:
    build:
      context: .
      dockerfile: docker/auth.Dockerfile
    container_name: hopper-auth
    ports:
      - "${AUTH_SERVICE_PORT:-5005}:5005"
    volumes:
      - ./src/auth:/app
      - ./data/auth:/data
    environment:
      - AUTH_SERVICE_PORT=5005
      - CONFIDENCE_THRESHOLD=${AUTH_CONFIDENCE_THRESHOLD:-0.85}
    env_file:
      - .env
    networks:
      - hopper-network
    restart: unless-stopped

  # Connecteurs (groupés pour Phase 1)
  connectors:
    build:
      context: .
      dockerfile: docker/connectors.Dockerfile
    container_name: hopper-connectors
    ports:
      - "5006:5006"
    volumes:
      - ./src/connectors:/app
      - ./config:/config
      - ./data/connectors:/data
    environment:
      - CONNECTOR_SERVICE_PORT=5006
    env_file:
      - .env
    networks:
      - hopper-network
    restart: unless-stopped

networks:
  hopper-network:
    driver: bridge

volumes:
  models:
  vector_store:
  auth_data:
