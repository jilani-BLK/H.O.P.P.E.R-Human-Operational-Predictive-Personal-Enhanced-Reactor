# ğŸ¤– ModÃ¨les LLM HOPPER

Les modÃ¨les LLM ne sont **pas versionnÃ©s dans Git** en raison de leur taille (4+ GB).

## ğŸ“¥ TÃ©lÃ©chargement

### Mistral 7B (RecommandÃ© - 4.1 GB)

```bash
# TÃ©lÃ©charger depuis Hugging Face
wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf \
  -O data/models/mistral-7b-instruct-v0.1.Q4_K_M.gguf
```

### LLaMA 2 7B (Alternative - 3.8 GB)

```bash
wget https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf \
  -O data/models/llama-2-7b-chat.Q4_K_M.gguf
```

## ğŸ³ Docker

Les modÃ¨les sont montÃ©s via volumes dans `docker-compose.yml`:

```yaml
volumes:
  - ./data/models:/app/data/models:ro
```

## ğŸ“‹ ModÃ¨les SupportÃ©s

- âœ… Mistral 7B Instruct (RecommandÃ©)
- âœ… LLaMA 2 7B Chat
- âœ… Tout modÃ¨le GGUF compatible llama.cpp
